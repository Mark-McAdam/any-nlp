{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "sample = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = [0,1,2,3]\n",
    "# review_names = ['excellent', 'good', 'bad']\n",
    "# train['ratingCategorical'] = pd.cut(train['ratingCategory'], bins, labels=review_names, include_lowest=True, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>\\nSometimes, when whisky is batched, a few lef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>\\nThis release is a port version of Amrut’s In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>\\nThis 41 year old single cask was aged in a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>\\nQuite herbal on the nose, with aromas of dri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  \\nSometimes, when whisky is batched, a few lef...               1\n",
       "1  3861  \\nAn uncommon exclusive bottling of a 6 year o...               0\n",
       "2   655  \\nThis release is a port version of Amrut’s In...               1\n",
       "3   555  \\nThis 41 year old single cask was aged in a s...               1\n",
       "4  1965  \\nQuite herbal on the nose, with aromas of dri...               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>\\nStyle: Speyside single malt scotch Color: Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>\\nVery bright and lively, with a nice balance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>\\nA new oloroso-forward Chivas positioned to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>\\nAged in bourbon casks and then enhanced in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>\\nThere is a freshness to the wood on the nose...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description\n",
       "0  3461  \\nStyle: Speyside single malt scotch Color: Wa...\n",
       "1  2604  \\nVery bright and lively, with a nice balance ...\n",
       "2  3341  \\nA new oloroso-forward Chivas positioned to s...\n",
       "3  3764  \\nAged in bourbon casks and then enhanced in R...\n",
       "4  2306  \\nThere is a freshness to the wood on the nose..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               2\n",
       "1  2604               2\n",
       "2  3341               2\n",
       "3  3764               2\n",
       "4  2306               2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(sen):\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['description'] = train['description'].apply(preprocess_text)\n",
    "test['description'] = test['description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train['ratingCategory']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"Multi class version of Logarithmic Loss metric.\n",
    "    :param actual: Array containing the actual target classes\n",
    "    :param predicted: Matrix with class predictions, one probability per class\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "4082    1\n",
      "4083    1\n",
      "4084    1\n",
      "4085    1\n",
      "4086    1\n",
      "Name: ratingCategory, Length: 4087, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO we may have to reassign y because I am not encoding the categorical anylonger \n",
    "# lbl_enc = preprocessing.LabelEncoder()\n",
    "# y = lbl_enc.fit_transform(train.ratingCategorical.values)\n",
    "\n",
    "y = train['ratingCategory']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>Sometimes when whisky is batched few leftover...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>An uncommon exclusive bottling of year old ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>This release is port version of Amrut Interme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>This year old single cask was aged in sherry ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>Quite herbal on the nose with aromas of dried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321   Sometimes when whisky is batched few leftover...               1\n",
       "1  3861   An uncommon exclusive bottling of year old ca...               0\n",
       "2   655   This release is port version of Amrut Interme...               1\n",
       "3   555   This year old single cask was aged in sherry ...               1\n",
       "4  1965   Quite herbal on the nose with aromas of dried...               1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4087, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.description.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' This is straightforward straight shootin Irish whiskey Creamy country fudge toasted muffins glorious sweet malt waxed lemons and delicate spices on the first sniff It light in the mouth with lemon curd juicy caramels and vanilla custard tarts simply bursting with warmth It concludes with spices twinkling on malt theme Have your Irish whiskey experiences only been with the big names Go live little You ought to get this sugar and spice and all things nice ',\n",
       "       ' Nashville restaurant Peg Leg Porker pitmaster Carey Bringle filters this whiskey through hickory charcoal Malted milk balls peanuts in the shell toasted grain Swiss Miss hot cocoa mix licorice root beer and tea leaves to start with lots of oak dark chocolate blackberry white pepper cinnamon cherry cough syrup and more root beer on the sweet spiced palate The finish is delicate and fruited with sweet cherries and blackberries as well as sprinkling of cloves and subtle oak ',\n",
       "       ' growing number of Canadian craft distillers are making Scotch style single malt whisky and several including Still Waters do quite good job of it Round leafy cereal notes on the nose give rise to granular fruitiness delicate oak caramels and glowering peppers on the palate It beautifully balanced lush and mouth filling and though delicious now with few more years it would be stellar Lovely hot peppers sweet grassiness yellow fruit and long spicy finish '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1362    1\n",
       "2710    1\n",
       "2490    1\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Stick your snout into aromas of rich tea biscuits honey tangerine toasted almond chips candied pineapple chunks and prickle of spice It youthful but integrated the grain domineering over the malt likable flavor sequence begins with lovely honey sweetness honeydew melon and pear before citrus phase followed by an ominous wave of spice which vanquishes the sweet fruits leaving swift spicy finish bottles for S ',\n",
       "       ' The appealing nose features pretty biscuit notes great purity of malt and golden honeyed sweetness before adding some flavors of citrus blossom clover and cardamom with hints of licorice On the palate the initial sweet malt quickly turns herbal with marjoram and distinct sage note that lingers through long finish of salt tinged sweetness Aged years months in full size charred oak ',\n",
       "       ' Independent bottler Gordon MacPhail offers variety of Balblair expressions including vintage and this year old in their Distillery Labels series Matured in mixture of refill sherry hogsheads and first fill bourbon barrels The nose offers rich warm fruits vanilla sherry maraschino cherries and ultimately toffee and orange blossom Medium bodied sweet and fruity with nutty milk chocolate white pepper and zesty spice Slowly drying in the finish with licorice and light oak '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvalid[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1286    1\n",
       "1585    1\n",
       "1950    1\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yvalid[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3678,)\n",
      "(409,)\n"
     ]
    }
   ],
   "source": [
    "print (xtrain.shape)\n",
    "print (xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.asarray(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Style Speyside single malt scotch Color Walnut Aroma Richly sherried and thick with notes of nuts and toffee Wood resins contribute spice and variety Fruitcake at Christmas Palate Thick chewy in texture and quite ripe Again the fruitcake Very deep and mature with some underlying maltiness Dry spicy oak notes fight off all that sherry and add balance and complexity Long soothing finish ',\n",
       "       ' Very bright and lively with nice balance of flavors Zesty fruit lemon peach ripe pineapple golden raisin on bed of layered sweetness creamy vanilla light honey lightly toasted marshmallow and hint of coconut Gently dry delicately spicy dried citrus finish Light enough and with enough zing to enjoy before dinner but it should stand up well enough after dinner too This is nice whisky but it shows lighter more elegant side of Glenrothes It doesn express the rich opulent notes often shown in bottlings like the Vintage for example ',\n",
       "       ' new oloroso forward Chivas positioned to split between the and year olds got this Refined and inviting nose of lemon pith black fruits and Kola Kubes The velvety texture is wonderfully smooth redolent of an apricot custard Danish lime zest raisin currant mixed peel and walnut with growing bitter lemon note Quite unique finish like sucking on lumpy Spanish lemons speckled with spices LA NY Miami Chicago Northern California but will go national '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)\n",
    "xtest_tfv = tfv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.556 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11911593, 0.87169094, 0.00919313],\n",
       "       [0.32056241, 0.66214529, 0.0172923 ],\n",
       "       [0.11200454, 0.88048324, 0.00751223],\n",
       "       ...,\n",
       "       [0.12922978, 0.8580907 , 0.01267952],\n",
       "       [0.44248012, 0.53661303, 0.02090685],\n",
       "       [0.1880043 , 0.80331342, 0.00868229]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = clf.predict_proba(xtest_tfv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24074484, 0.74598284, 0.01327232],\n",
       "       [0.30008709, 0.68704451, 0.01286839],\n",
       "       [0.24420319, 0.74293926, 0.01285756],\n",
       "       ...,\n",
       "       [0.23473   , 0.74623609, 0.01903391],\n",
       "       [0.28933964, 0.69529618, 0.01536418],\n",
       "       [0.52683154, 0.42925388, 0.04391458]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "labels = np.argmax(test_predictions, axis=-1)    \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory\n",
       "0  3461               2\n",
       "1  2604               2\n",
       "2  3341               2\n",
       "3  3764               2\n",
       "4  2306               2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['rating']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory  rating\n",
       "0  3461               2       1\n",
       "1  2604               2       1\n",
       "2  3341               2       1\n",
       "3  3764               2       1\n",
       "4  2306               2       1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2be31f60>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='rating', data=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    901\n",
       "0    121\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Think got a 56% first run round \n",
    "# then 55.6% ok moving right along "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3678x16029 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 202871 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<409x16029 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22814 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvalid_tfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x16029 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 51866 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_tfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory  rating\n",
       "0  3461               2       1\n",
       "1  2604               2       1\n",
       "2  3341               2       1\n",
       "3  3764               2       1\n",
       "4  2306               2       1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  ratingCategory  rating\n",
       "0  3461               2       1\n",
       "1  2604               2       1\n",
       "2  3341               2       1\n",
       "3  3764               2       1\n",
       "4  2306               2       1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sample['ratingCategory']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.rename(columns = {'rating':'ratingCategory'}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>2853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2201</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>4019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  ratingCategory\n",
       "0     3461               1\n",
       "1     2604               1\n",
       "2     3341               1\n",
       "3     3764               1\n",
       "4     2306               1\n",
       "...    ...             ...\n",
       "1017  2853               1\n",
       "1018   219               1\n",
       "1019  1286               1\n",
       "1020  2201               1\n",
       "1021  4019               0\n",
       "\n",
       "[1022 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':sample['ratingCategory']})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "\n",
    "submission.to_csv(f'../data/submission{subNumber}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next \n",
    "instead of tfidf\n",
    "word counts as features\n",
    "using CountVectorizer from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), stop_words = 'english')\n",
    "\n",
    "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n",
    "ctv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_ctv =  ctv.transform(xtrain) \n",
    "xvalid_ctv = ctv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.636 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on Counts\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc 63.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.683 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on TFIDF\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc 68.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 3.695 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Naive Bayes on Counts\n",
    "clf = MultinomialNB()\n",
    "clf.fit(xtrain_ctv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SVD and then simple SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SVD, I chose 120 components. 120-200 components are good enough for SVM model.\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(xtrain_tfv)\n",
    "xtrain_svd = svd.transform(xtrain_tfv)\n",
    "xvalid_svd = svd.transform(xvalid_tfv)\n",
    "\n",
    "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(xtrain_svd)\n",
    "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
    "xvalid_svd_scl = scl.transform(xvalid_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.534 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple SVM\n",
    "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
    "clf.fit(xtrain_svd_scl, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd_scl)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.580 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_tfv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv.tocsc())\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.585 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_ctv.tocsc(), ytrain)\n",
    "predictions = clf.predict_proba(xvalid_ctv.tocsc())\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.646 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.672 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on tf-idf svd features\n",
    "clf = xgb.XGBClassifier(nthread=10)\n",
    "clf.fit(xtrain_svd, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_svd)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving onto pipelines \n",
    "\n",
    "so far the best performing has been XG boost on tf-idf svd features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVD\n",
    "svd = TruncatedSVD()\n",
    "    \n",
    "# Initialize the standard scaler \n",
    "scl = preprocessing.StandardScaler()\n",
    "\n",
    "# We will use logistic regression here..\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('scl', scl),\n",
    "                         ('lr', lr_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'svd__n_components' : [120, 180],\n",
    "              'lr__C': [0.1, 1.0, 10], \n",
    "              'lr__penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  24 | elapsed:    6.7s remaining:    6.7s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  24 | elapsed:    7.2s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  24 | elapsed:    8.0s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  24 | elapsed:    8.8s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.586\n",
      "Best parameters set:\n",
      "\tlr__C: 0.1\n",
      "\tlr__penalty: 'l2'\n",
      "\tsvd__n_components: 120\n"
     ]
    }
   ],
   "source": [
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain\n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next pipeline attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "Best score: -0.650\n",
      "Best parameters set:\n",
      "\tnb__alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0472s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  12 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  12 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('nb', nb_model)])\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
    "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain. \n",
    "print(\"Best score: %0.3f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOVE VECTORS !!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [03:00, 12141.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196007 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from numpy import asarray\n",
    "\n",
    "# load the GloVe vectors in a dictionary:\n",
    "\n",
    "# embeddings_index = {}\n",
    "# f = open('glove.840B.300d.txt')\n",
    "# for line in tqdm(f):\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "\n",
    "# l.decode('utf8').strip().split(' ')\n",
    "embeddings_index = {}\n",
    "f = open('glove.840B.300d.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.strip().split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function creates a normalized vector for the whole sentence\n",
    "def sent2vec(s):\n",
    "    words = str(s).lower() # commented out decode .decode('utf-8')\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(300)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mark/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3678/3678 [00:02<00:00, 1430.46it/s]\n",
      "100%|██████████| 409/409 [00:00<00:00, 1488.46it/s]\n",
      "100%|██████████| 1022/1022 [00:01<00:00, 918.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# create sentence vectors using the above function for training and validation set\n",
    "xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n",
    "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]\n",
    "xtest_glove = [sent2vec(x) for x in tqdm(xtest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_glove = np.array(xtrain_glove)\n",
    "xvalid_glove = np.array(xvalid_glove)\n",
    "xtest_glove = np.array(xtest_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-69-2719983566c3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-69-2719983566c3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    error for stop\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost on GLOVE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.745 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on glove features\n",
    "clf = xgb.XGBClassifier(nthread=10, silent=False)\n",
    "clf.fit(xtrain_glove, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_glove)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!!  Stop here and make a prediction. loglogg 0.745 !!! ------------------- *** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "test_predictions = clf.predict_proba(xtest_glove)\n",
    "labels = np.argmax(test_predictions, axis=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/submission{subNumber}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    866\n",
       "0    156\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAP3UlEQVR4nO3dfZBddX3H8fdHAiIoj9lSCbRhlKFD1YpGxNqxM2KrYDXUKuKUGm1m0plSlWJbY9upVTutj6UordNoRHDQiqCCHau1POhUEZsIQki0ZpCHIA9RAVEHbfDbP+4vPzZhSS7C2btk36+ZO/t7Oud+lyz72XPOveemqpAkCeBRky5AkjR3GAqSpM5QkCR1hoIkqTMUJEndgkkX8FAsXLiwFi9ePOkyJOkRZe3atd+tqqmZ5h7RobB48WLWrFkz6TIk6RElyQ0PNOfpI0lSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVL3iH5Hs7Qru/EtT550CZqDfulvrhl0/x4pSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpG7QUEjyp0muTbIuyUeT7JnksCRXJNmY5GNJ9mhrH936G9v84iFrkyTd32ChkGQR8FpgSVU9CdgNOAl4O3B6VT0RuANY3jZZDtzRxk9v6yRJs2jo00cLgMckWQDsBdwCPBc4v82fDZzQ2ktbnzZ/bJIMXJ8kaZrBQqGqbgbeBdzIKAzuAtYCd1bVlrZsE7CotRcBN7Vtt7T1B26/3yQrkqxJsmbz5s1DlS9J89KQp4/2Z/TX/2HAwcDewAse6n6ralVVLamqJVNTUw91d5KkaYY8ffQ84NtVtbmq/g/4BPBsYL92OgngEODm1r4ZOBSgze8LfG/A+iRJ2xkyFG4EjkmyV7s2cCywHrgUeGlbswy4sLUvan3a/CVVVQPWJ0nazpDXFK5gdMH4a8A17blWAW8ATkuykdE1g9Vtk9XAgW38NGDlULVJkmY26Gc0V9WbgDdtN3wdcPQMa+8BXjZkPZKkHfMdzZKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkrpBQyHJfknOT/KNJBuSPCvJAUk+n+Rb7ev+bW2SvCfJxiRXJ3nakLVJku5v6COFM4DPVtWvAL8GbABWAhdX1eHAxa0PcBxweHusAN43cG2SpO0MFgpJ9gWeA6wGqKqfVtWdwFLg7LbsbOCE1l4KnFMjXwH2S/L4oeqTJN3fkEcKhwGbgbOSXJnkA0n2Bg6qqlvamluBg1p7EXDTtO03tbFtJFmRZE2SNZs3bx6wfEmaf4YMhQXA04D3VdVRwI+471QRAFVVQD2YnVbVqqpaUlVLpqamHrZiJUnDhsImYFNVXdH65zMKidu2nhZqX29v8zcDh07b/pA2JkmaJYOFQlXdCtyU5Ig2dCywHrgIWNbGlgEXtvZFwCvbq5COAe6adppJkjQLFgy8/9cA5ybZA7gOeDWjIDovyXLgBuDEtvYzwPHARuDHba0kaRYNGgpVdRWwZIapY2dYW8ApQ9YjSdox39EsSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUjdWKCS5eJwxSdIj2w4/oznJnsBewMIk+wNpU/sAiwauTZI0y3YYCsAfAacCBwNruS8UfgCcOWBdkqQJ2GEoVNUZwBlJXlNV752lmiRJE7KzIwUAquq9SX4dWDx9m6o6Z6C6JEkTMFYoJPkw8ATgKuDeNlyAoSBJu5CxQgFYAhxZVTVkMZKkyRr3fQrrgF8cshBJ0uSNe6SwEFif5KvAT7YOVtWLB6lKkjQR44bC3w5ZhCRpbhj31UdfGLoQSdLkjfvqo7sZvdoIYA9gd+BHVbXPUIVJkmbfuEcKj9vaThJgKXDMUEVJkibjQd8ltUY+BTx/gHokSRM07umjl0zrPorR+xbuGaQiSdLEjPvqoxdNa28Brmd0CkmStAsZ95rCq4cuRJI0eeN+yM4hST6Z5Pb2uCDJIUMXJ0maXeNeaD4LuIjR5yocDHy6jUmSdiHjhsJUVZ1VVVva40PA1IB1SZImYNxQ+F6Sk5Ps1h4nA98bsjBJ0uwbNxT+EDgRuBW4BXgp8KpxNmwhcmWSf2/9w5JckWRjko8l2aONP7r1N7b5xQ/ye5EkPUTjhsJbgGVVNVVVv8AoJN485ravAzZM678dOL2qngjcASxv48uBO9r46W2dJGkWjRsKT6mqO7Z2qur7wFE726i9QumFwAdaP8BzgfPbkrOBE1p7aevT5o9t6yVJs2TcUHhUkv23dpIcwHjvcfgn4C+An7X+gcCdVbWl9TcBi1p7EXATQJu/q63fRpIVSdYkWbN58+Yxy5ckjWPcUHg3cHmStyZ5K/Bl4B072iDJ7wC3V9Xah1jjNqpqVVUtqaolU1O+AEqSHk7jvqP5nCRrGJ36AXhJVa3fyWbPBl6c5HhgT2Af4AxgvyQL2tHAIcDNbf3NwKHApiQLgH3xFU6SNKvGvktqVa2vqjPbY2eBQFW9saoOqarFwEnAJVX1+8CljF69BLAMuLC1L2p92vwlVVVIkmbNg7519sPgDcBpSTYyumawuo2vBg5s46cBKydQmyTNa+PeJfUhqarLgMta+zrg6BnW3AO8bDbqkSTNbBJHCpKkOcpQkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJK6wUIhyaFJLk2yPsm1SV7Xxg9I8vkk32pf92/jSfKeJBuTXJ3kaUPVJkma2ZBHCluA11fVkcAxwClJjgRWAhdX1eHAxa0PcBxweHusAN43YG2SpBkMFgpVdUtVfa217wY2AIuApcDZbdnZwAmtvRQ4p0a+AuyX5PFD1SdJur9ZuaaQZDFwFHAFcFBV3dKmbgUOau1FwE3TNtvUxrbf14oka5Ks2bx582A1S9J8NHgoJHkscAFwalX9YPpcVRVQD2Z/VbWqqpZU1ZKpqamHsVJJ0qChkGR3RoFwblV9og3ftvW0UPt6exu/GTh02uaHtDFJ0iwZ8tVHAVYDG6rqH6dNXQQsa+1lwIXTxl/ZXoV0DHDXtNNMkqRZsGDAfT8b+APgmiRXtbG/BN4GnJdkOXADcGKb+wxwPLAR+DHw6gFrkyTNYLBQqKr/BvIA08fOsL6AU4aqR5K0c76jWZLUGQqSpM5QkCR1hoIkqRvy1UePCE//83MmXYLmoLXvfOWkS5AmwiMFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJK6ORUKSV6Q5JtJNiZZOel6JGm+mTOhkGQ34J+B44AjgVckOXKyVUnS/DJnQgE4GthYVddV1U+BfwOWTrgmSZpXFky6gGkWATdN628Cnrn9oiQrgBWt+8Mk35yF2uaLhcB3J13EXJB3LZt0CdqWP5tbvSkPx15++YEm5lIojKWqVgGrJl3HrijJmqpaMuk6pO35szl75tLpo5uBQ6f1D2ljkqRZMpdC4X+Aw5MclmQP4CTgognXJEnzypw5fVRVW5L8CfA5YDfgg1V17YTLmm88Lae5yp/NWZKqmnQNkqQ5Yi6dPpIkTZihIEnqDAV5exHNWUk+mOT2JOsmXct8YSjMc95eRHPch4AXTLqI+cRQkLcX0ZxVVV8Evj/pOuYTQ0Ez3V5k0YRqkTRhhoIkqTMU5O1FJHWGgry9iKTOUJjnqmoLsPX2IhuA87y9iOaKJB8FLgeOSLIpyfJJ17Sr8zYXkqTOIwVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaC5pUkpybZa1r/M0n2ewj7OzrJF9tdZq9M8oHp+59h/VOTHP/zPp80NENBu5yMPNDP9qlA/6VdVcdX1Z0/5/McBHwceENVHVFVRwGfBR63g82eCgweCu3ut9KDZihol5Bkcftr/RxgHbA6yZok1yZ5c1vzWuBg4NIkl7ax65MsbNtvSPL+ts1/JnlMW/OMJFcnuSrJO6fd2/8U4OyqunxrHVV1flXd1o4gLm9HD19OckR7x/hbgJe3fb08yd7tMwO+2tYubc+5V5LzkqxP8skkVyRZ0uZekeSaJOuSvH3af4MfJnl3kq8Df5XkU9PmfivJJwf7B9Cuo6p8+HjEP4DFwM+AY1r/gPZ1N+Ay4Cmtfz2wcNp21wML2/ZbgKe28fOAk1t7HfCs1n4bsK61PwEsfYB69gEWtPbzgAta+1XAmdPW/f2059kP+F9gb+DPgH9t409qtS1hFGo3AlPAAuAS4IS2roATWzvAN4Cp1v8I8KJJ/zv5mPsPjxS0K7mhqr7S2icm+RpwJfCrjD5AaGe+XVVXtfZaYHG73vC4uu9o4CNj1rIv8PF2VHF6q2Emvw2sTHIVo/DaE/gl4DcYfbYFVbUOuLqtfwZwWVVtrtEtSs4FntPm7gUuaNsU8GHg5PY9PAv4jzFr1zy2YNIFSA+jHwEkOYzRX9rPqKo7knyI0S/bnfnJtPa9wGN2sv5a4OnAhTPMvRW4tKp+N8liRr/wZxLg96rqm9sMJmOUez/3VNW90/pnAZ8G7gE+3kJE2iGPFLQr2odRQNzVLgYfN23ubnZ8IXgbNboIfXeSZ7ahk6ZNnwksmzZHkpe059yX+25B/qodPP/ngNekpUCSo9r4l4AT29iRwJPb+FeB32zXQXYDXgF84QFq/w7wHeCvGQWEtFOGgnY5VfV1RqeNvsHodM+Xpk2vAj679ULzmJYD72+nePYG7mrPcxujkHhXu8i9AXg+o1/87wD+IcmVbHtEfilw5NYLzYyOKHYHrk5ybesD/AswlWQ98HeMjkruqqpbgJVtP18H1lbVTEcqW50L3FRVGx7E96t5zLukSjuR5LFV9cPWXgk8vqpeN/Bz7gbsXlX3JHkC8F/AETX6HO0Hs58zgSuravUQdWrX4zUFaedemOSNjP5/uYFtTwcNZS9GL53dndF1hz/+OQJhLaPTaK8foD7tojxSkCR1XlOQJHWGgiSpMxQkSZ2hIEnqDAVJUvf/YQPC2pACSW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.693 \n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple xgboost on glove features\n",
    "clf = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n",
    "                        subsample=0.8, nthread=10, learning_rate=0.1, silent=False)\n",
    "clf.fit(xtrain_glove, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_glove)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "test_predictions = clf.predict_proba(xtest_glove)\n",
    "labels = np.argmax(test_predictions, axis=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/submission{subNumber}.csv', index=False)\n",
    "print(subNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    878\n",
       "0    144\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data before any neural net:\n",
    "scl = preprocessing.StandardScaler()\n",
    "xtrain_glove_scl = scl.fit_transform(xtrain_glove)\n",
    "xvalid_glove_scl = scl.transform(xvalid_glove)\n",
    "xtest_glove_scl = scl.transform(xtest_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to binarize the labels for the neural net\n",
    "ytrain_enc = np_utils.to_categorical(ytrain)\n",
    "yvalid_enc = np_utils.to_categorical(yvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple 3 layer sequential neural net\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(300, input_dim=300, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3678 samples, validate on 409 samples\n",
      "Epoch 1/15\n",
      "3678/3678 [==============================] - 0s 84us/step - loss: 0.4089 - val_loss: 0.5977\n",
      "Epoch 2/15\n",
      "3678/3678 [==============================] - 0s 79us/step - loss: 0.3590 - val_loss: 0.6266\n",
      "Epoch 3/15\n",
      "3678/3678 [==============================] - 0s 76us/step - loss: 0.3240 - val_loss: 0.6398\n",
      "Epoch 4/15\n",
      "3678/3678 [==============================] - 0s 76us/step - loss: 0.3012 - val_loss: 0.6613\n",
      "Epoch 5/15\n",
      "3678/3678 [==============================] - 0s 74us/step - loss: 0.2888 - val_loss: 0.6403\n",
      "Epoch 6/15\n",
      "3678/3678 [==============================] - 0s 79us/step - loss: 0.2435 - val_loss: 0.6547\n",
      "Epoch 7/15\n",
      "3678/3678 [==============================] - 0s 76us/step - loss: 0.2194 - val_loss: 0.7095\n",
      "Epoch 8/15\n",
      "3678/3678 [==============================] - 0s 75us/step - loss: 0.2106 - val_loss: 0.7641\n",
      "Epoch 9/15\n",
      "3678/3678 [==============================] - 0s 75us/step - loss: 0.1859 - val_loss: 0.7405\n",
      "Epoch 10/15\n",
      "3678/3678 [==============================] - 0s 72us/step - loss: 0.1640 - val_loss: 0.7629\n",
      "Epoch 11/15\n",
      "3678/3678 [==============================] - 0s 75us/step - loss: 0.1594 - val_loss: 0.8356\n",
      "Epoch 12/15\n",
      "3678/3678 [==============================] - 0s 74us/step - loss: 0.1362 - val_loss: 0.8618\n",
      "Epoch 13/15\n",
      "3678/3678 [==============================] - 0s 80us/step - loss: 0.1430 - val_loss: 0.8386\n",
      "Epoch 14/15\n",
      "3678/3678 [==============================] - 0s 76us/step - loss: 0.1379 - val_loss: 0.8540\n",
      "Epoch 15/15\n",
      "3678/3678 [==============================] - 0s 77us/step - loss: 0.1174 - val_loss: 0.8488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a404206d8>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_glove_scl, y=ytrain_enc, batch_size=64, \n",
    "          epochs=15, verbose=1, \n",
    "          validation_data=(xvalid_glove_scl, yvalid_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get accuracy and a submission before moving on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------- ** --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "test_predictions = model.predict_proba(xtest_glove_scl)\n",
    "labels = np.argmax(test_predictions, axis=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1006\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/deepsub{subNumber}.csv', index=False)\n",
    "print(subNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    742\n",
       "0    278\n",
       "2      2\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 70\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "xtest_seq = token.texts_to_sequences(xtest)\n",
    "\n",
    "\n",
    "# zero pad the sequences\n",
    "xtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "xtest_pad = sequence.pad_sequences(xtest_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12377/12377 [00:00<00:00, 52279.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple LSTM with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3678 samples, validate on 409 samples\n",
      "Epoch 1/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.8134 - val_loss: 0.6947\n",
      "Epoch 2/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.7008 - val_loss: 0.6564\n",
      "Epoch 3/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.6749 - val_loss: 0.6726\n",
      "Epoch 4/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.6662 - val_loss: 0.6533\n",
      "Epoch 5/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.6603 - val_loss: 0.6476\n",
      "Epoch 6/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.6500 - val_loss: 0.6293\n",
      "Epoch 7/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.6484 - val_loss: 0.6133\n",
      "Epoch 8/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.6370 - val_loss: 0.5965\n",
      "Epoch 9/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.6289 - val_loss: 0.6045\n",
      "Epoch 10/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.6281 - val_loss: 0.5780\n",
      "Epoch 11/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.6241 - val_loss: 0.5871\n",
      "Epoch 12/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.6186 - val_loss: 0.5817\n",
      "Epoch 13/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.6173 - val_loss: 0.5952\n",
      "Epoch 14/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.6092 - val_loss: 0.5708\n",
      "Epoch 15/100\n",
      "3678/3678 [==============================] - 6s 2ms/step - loss: 0.6095 - val_loss: 0.5654\n",
      "Epoch 16/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5976 - val_loss: 0.5618\n",
      "Epoch 17/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5966 - val_loss: 0.5681\n",
      "Epoch 18/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.6029 - val_loss: 0.5602\n",
      "Epoch 19/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.6047 - val_loss: 0.5874\n",
      "Epoch 20/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5981 - val_loss: 0.5594\n",
      "Epoch 21/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5857 - val_loss: 0.5567\n",
      "Epoch 22/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5779 - val_loss: 0.5599\n",
      "Epoch 23/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5816 - val_loss: 0.5526\n",
      "Epoch 24/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5734 - val_loss: 0.5483\n",
      "Epoch 25/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5764 - val_loss: 0.5516\n",
      "Epoch 26/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5763 - val_loss: 0.5529\n",
      "Epoch 27/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5627 - val_loss: 0.5441\n",
      "Epoch 28/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5699 - val_loss: 0.5476\n",
      "Epoch 29/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5600 - val_loss: 0.5346\n",
      "Epoch 30/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5497 - val_loss: 0.5397\n",
      "Epoch 31/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5522 - val_loss: 0.5456\n",
      "Epoch 32/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5532 - val_loss: 0.5419\n",
      "Epoch 33/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5438 - val_loss: 0.5402\n",
      "Epoch 34/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5483 - val_loss: 0.5469\n",
      "Epoch 35/100\n",
      "3678/3678 [==============================] - 6s 2ms/step - loss: 0.5517 - val_loss: 0.5471\n",
      "Epoch 36/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5394 - val_loss: 0.5443\n",
      "Epoch 37/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5321 - val_loss: 0.5358\n",
      "Epoch 38/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.5381 - val_loss: 0.5403\n",
      "Epoch 39/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5203 - val_loss: 0.5346\n",
      "Epoch 40/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5108 - val_loss: 0.5478\n",
      "Epoch 41/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5201 - val_loss: 0.5330\n",
      "Epoch 42/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5085 - val_loss: 0.5334\n",
      "Epoch 43/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5084 - val_loss: 0.5379\n",
      "Epoch 44/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.5026 - val_loss: 0.5295\n",
      "Epoch 45/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4987 - val_loss: 0.5329\n",
      "Epoch 46/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4908 - val_loss: 0.5357\n",
      "Epoch 47/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4965 - val_loss: 0.5435\n",
      "Epoch 48/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4899 - val_loss: 0.5414\n",
      "Epoch 49/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4774 - val_loss: 0.5318\n",
      "Epoch 50/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4862 - val_loss: 0.5374\n",
      "Epoch 51/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4855 - val_loss: 0.5340\n",
      "Epoch 52/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4705 - val_loss: 0.5308\n",
      "Epoch 53/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4792 - val_loss: 0.5411\n",
      "Epoch 54/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4645 - val_loss: 0.5446\n",
      "Epoch 55/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4648 - val_loss: 0.5362\n",
      "Epoch 56/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4478 - val_loss: 0.5382\n",
      "Epoch 57/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4487 - val_loss: 0.5445\n",
      "Epoch 58/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4387 - val_loss: 0.5515\n",
      "Epoch 59/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4659 - val_loss: 0.5479\n",
      "Epoch 60/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4474 - val_loss: 0.5395\n",
      "Epoch 61/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4406 - val_loss: 0.5362\n",
      "Epoch 62/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4414 - val_loss: 0.5533\n",
      "Epoch 63/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4409 - val_loss: 0.5387\n",
      "Epoch 64/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4195 - val_loss: 0.5533\n",
      "Epoch 65/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4044 - val_loss: 0.5538\n",
      "Epoch 66/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4149 - val_loss: 0.5589\n",
      "Epoch 67/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4230 - val_loss: 0.5836\n",
      "Epoch 68/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4071 - val_loss: 0.5543\n",
      "Epoch 69/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4117 - val_loss: 0.5683\n",
      "Epoch 70/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3963 - val_loss: 0.5645\n",
      "Epoch 71/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3861 - val_loss: 0.5796\n",
      "Epoch 72/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.4034 - val_loss: 0.5691\n",
      "Epoch 73/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3713 - val_loss: 0.5579\n",
      "Epoch 74/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3821 - val_loss: 0.5792\n",
      "Epoch 75/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3643 - val_loss: 0.5747\n",
      "Epoch 76/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3669 - val_loss: 0.5914\n",
      "Epoch 77/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3592 - val_loss: 0.6019\n",
      "Epoch 78/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3608 - val_loss: 0.6128\n",
      "Epoch 79/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3574 - val_loss: 0.6164\n",
      "Epoch 80/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3394 - val_loss: 0.5999\n",
      "Epoch 81/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3477 - val_loss: 0.5848\n",
      "Epoch 82/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3319 - val_loss: 0.6273\n",
      "Epoch 83/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3290 - val_loss: 0.6294\n",
      "Epoch 84/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3302 - val_loss: 0.6475\n",
      "Epoch 85/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3333 - val_loss: 0.6241\n",
      "Epoch 86/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3115 - val_loss: 0.6095\n",
      "Epoch 87/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3080 - val_loss: 0.6386\n",
      "Epoch 88/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3307 - val_loss: 0.6340\n",
      "Epoch 89/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3018 - val_loss: 0.6333\n",
      "Epoch 90/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3017 - val_loss: 0.6671\n",
      "Epoch 91/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3024 - val_loss: 0.6520\n",
      "Epoch 92/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.2999 - val_loss: 0.6743\n",
      "Epoch 93/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.3123 - val_loss: 0.6617\n",
      "Epoch 94/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.2821 - val_loss: 0.6921\n",
      "Epoch 95/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.2956 - val_loss: 0.6706\n",
      "Epoch 96/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.2772 - val_loss: 0.6666\n",
      "Epoch 97/100\n",
      "3678/3678 [==============================] - 5s 1ms/step - loss: 0.2864 - val_loss: 0.6800\n",
      "Epoch 98/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.2777 - val_loss: 0.7171\n",
      "Epoch 99/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.2799 - val_loss: 0.6999\n",
      "Epoch 100/100\n",
      "3678/3678 [==============================] - 4s 1ms/step - loss: 0.2601 - val_loss: 0.7225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a57dffc18>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, verbose=1, validation_data=(xvalid_pad, yvalid_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "test_predictions = model.predict_proba(xtest_pad)\n",
    "labels = np.argmax(test_predictions, axis=-1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/deepsub{subNumber}.csv', index=False)\n",
    "print(subNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    752\n",
       "0    268\n",
       "2      2\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Early Stopping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the score is now less than 0.5. I ran it for many epochs without stopping at the best but you can use early stopping to stop at the best iteration. How do I use early stopping?\n",
    "\n",
    "well, pretty easy. let's compile the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple LSTM with glove embeddings and two dense layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3678 samples, validate on 409 samples\n",
      "Epoch 1/100\n",
      "3678/3678 [==============================] - 13s 4ms/step - loss: 0.7794 - val_loss: 0.6766\n",
      "Epoch 2/100\n",
      "3678/3678 [==============================] - 13s 3ms/step - loss: 0.6850 - val_loss: 0.6749\n",
      "Epoch 3/100\n",
      "3678/3678 [==============================] - 14s 4ms/step - loss: 0.6684 - val_loss: 0.6710\n",
      "Epoch 4/100\n",
      "3678/3678 [==============================] - 14s 4ms/step - loss: 0.6663 - val_loss: 0.6384\n",
      "Epoch 5/100\n",
      "3678/3678 [==============================] - 14s 4ms/step - loss: 0.6513 - val_loss: 0.6268\n",
      "Epoch 6/100\n",
      "3678/3678 [==============================] - 14s 4ms/step - loss: 0.6399 - val_loss: 0.5925\n",
      "Epoch 7/100\n",
      "3678/3678 [==============================] - 13s 4ms/step - loss: 0.6362 - val_loss: 0.5869\n",
      "Epoch 8/100\n",
      "3678/3678 [==============================] - 13s 3ms/step - loss: 0.6281 - val_loss: 0.5951\n",
      "Epoch 9/100\n",
      "3678/3678 [==============================] - 13s 4ms/step - loss: 0.6475 - val_loss: 0.5924\n",
      "Epoch 10/100\n",
      "3678/3678 [==============================] - 13s 4ms/step - loss: 0.6266 - val_loss: 0.5960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a5ec434a8>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "test_predictions = model.predict_proba(xtest_pad)\n",
    "labels = np.argmax(test_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/deepsub{subNumber}.csv', index=False)\n",
    "print(subNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    859\n",
       "0    163\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple bidirectional LSTM with glove embeddings and two dense layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3678 samples, validate on 409 samples\n",
      "Epoch 1/100\n",
      "3678/3678 [==============================] - 31s 8ms/step - loss: 0.8207 - val_loss: 0.7126\n",
      "Epoch 2/100\n",
      "3678/3678 [==============================] - 29s 8ms/step - loss: 0.6969 - val_loss: 0.6692\n",
      "Epoch 3/100\n",
      "3678/3678 [==============================] - 26s 7ms/step - loss: 0.6784 - val_loss: 0.6488\n",
      "Epoch 4/100\n",
      "3678/3678 [==============================] - 25s 7ms/step - loss: 0.6687 - val_loss: 0.6339\n",
      "Epoch 5/100\n",
      "3678/3678 [==============================] - 24s 6ms/step - loss: 0.6557 - val_loss: 0.6475\n",
      "Epoch 6/100\n",
      "3678/3678 [==============================] - 25s 7ms/step - loss: 0.6458 - val_loss: 0.6016\n",
      "Epoch 7/100\n",
      "3678/3678 [==============================] - 25s 7ms/step - loss: 0.6372 - val_loss: 0.5844\n",
      "Epoch 8/100\n",
      "3678/3678 [==============================] - 27s 7ms/step - loss: 0.6207 - val_loss: 0.5794\n",
      "Epoch 9/100\n",
      "3678/3678 [==============================] - 28s 8ms/step - loss: 0.6106 - val_loss: 0.5776\n",
      "Epoch 10/100\n",
      "3678/3678 [==============================] - 27s 7ms/step - loss: 0.6012 - val_loss: 0.5672\n",
      "Epoch 11/100\n",
      "3678/3678 [==============================] - 27s 7ms/step - loss: 0.5934 - val_loss: 0.6009\n",
      "Epoch 12/100\n",
      "3678/3678 [==============================] - 25s 7ms/step - loss: 0.5938 - val_loss: 0.6170\n",
      "Epoch 13/100\n",
      "3678/3678 [==============================] - 26s 7ms/step - loss: 0.6072 - val_loss: 0.6073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a5f62c7b8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "test_predictions = model.predict_proba(xtest_pad)\n",
    "labels = np.argmax(test_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1009\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/deepsub{subNumber}.csv', index=False)\n",
    "print(subNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    783\n",
       "0    239\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 GRU and Two Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3678 samples, validate on 409 samples\n",
      "Epoch 1/100\n",
      "3678/3678 [==============================] - 26s 7ms/step - loss: 8.8135 - val_loss: 0.8121\n",
      "Epoch 2/100\n",
      "3678/3678 [==============================] - 26s 7ms/step - loss: 5.6153 - val_loss: 0.7471\n",
      "Epoch 3/100\n",
      "3678/3678 [==============================] - 24s 6ms/step - loss: 5.5030 - val_loss: 0.7167\n",
      "Epoch 4/100\n",
      "3678/3678 [==============================] - 25s 7ms/step - loss: 5.3194 - val_loss: 0.7100\n",
      "Epoch 5/100\n",
      "3678/3678 [==============================] - 23s 6ms/step - loss: 6.0983 - val_loss: 0.7204\n",
      "Epoch 6/100\n",
      "3678/3678 [==============================] - 23s 6ms/step - loss: 5.8313 - val_loss: 0.7019\n",
      "Epoch 7/100\n",
      "3678/3678 [==============================] - 22s 6ms/step - loss: 5.8204 - val_loss: 0.7271\n",
      "Epoch 8/100\n",
      "3678/3678 [==============================] - 22s 6ms/step - loss: 6.1869 - val_loss: 0.7120\n",
      "Epoch 9/100\n",
      "3678/3678 [==============================] - 23s 6ms/step - loss: 5.7118 - val_loss: 0.6655\n",
      "Epoch 10/100\n",
      "3678/3678 [==============================] - 25s 7ms/step - loss: 5.6356 - val_loss: 0.6783\n",
      "Epoch 11/100\n",
      "3678/3678 [==============================] - 21s 6ms/step - loss: 5.6006 - val_loss: 0.6917\n",
      "Epoch 12/100\n",
      "3678/3678 [==============================] - 21s 6ms/step - loss: 5.4779 - val_loss: 0.6993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a6334cf98>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GRU with glove embeddings and two dense layers\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))\n",
    "model.add(GRU(300, dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Fit the model with early stopping callback\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "model.fit(xtrain_pad, y=ytrain_enc, batch_size=512, epochs=100, \n",
    "          verbose=1, validation_data=(xvalid_pad, yvalid_enc), callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "test_predictions = model.predict_proba(xtest_pad)\n",
    "labels = np.argmax(test_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/deepsub{subNumber}.csv', index=False)\n",
    "print(subNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1022\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the main ensembling class. how to use it is in the next cell!\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"[%(asctime)s] %(levelname)s %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\", stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Ensembler(object):\n",
    "    def __init__(self, model_dict, num_folds=3, task_type='classification', optimize=roc_auc_score,\n",
    "                 lower_is_better=False, save_path=None):\n",
    "        \"\"\"\n",
    "        Ensembler init function\n",
    "        :param model_dict: model dictionary, see README for its format\n",
    "        :param num_folds: the number of folds for ensembling\n",
    "        :param task_type: classification or regression\n",
    "        :param optimize: the function to optimize for, e.g. AUC, logloss, etc. Must have two arguments y_test and y_pred\n",
    "        :param lower_is_better: is lower value of optimization function better or higher\n",
    "        :param save_path: path to which model pickles will be dumped to along with generated predictions, or None\n",
    "        \"\"\"\n",
    "\n",
    "        self.model_dict = model_dict\n",
    "        self.levels = len(self.model_dict)\n",
    "        self.num_folds = num_folds\n",
    "        self.task_type = task_type\n",
    "        self.optimize = optimize\n",
    "        self.lower_is_better = lower_is_better\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.training_data = None\n",
    "        self.test_data = None\n",
    "        self.y = None\n",
    "        self.lbl_enc = None\n",
    "        self.y_enc = None\n",
    "        self.train_prediction_dict = None\n",
    "        self.test_prediction_dict = None\n",
    "        self.num_classes = None\n",
    "\n",
    "    def fit(self, training_data, y, lentrain):\n",
    "        \"\"\"\n",
    "        :param training_data: training data in tabular format\n",
    "        :param y: binary, multi-class or regression\n",
    "        :return: chain of models to be used in prediction\n",
    "        \"\"\"\n",
    "\n",
    "        self.training_data = training_data\n",
    "        self.y = y\n",
    "\n",
    "        if self.task_type == 'classification':\n",
    "            self.num_classes = len(np.unique(self.y))\n",
    "            logger.info(\"Found %d classes\", self.num_classes)\n",
    "            self.lbl_enc = LabelEncoder()\n",
    "            self.y_enc = self.lbl_enc.fit_transform(self.y)\n",
    "            kf = StratifiedKFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, self.num_classes)\n",
    "        else:\n",
    "            self.num_classes = -1\n",
    "            self.y_enc = self.y\n",
    "            kf = KFold(n_splits=self.num_folds)\n",
    "            train_prediction_shape = (lentrain, 1)\n",
    "\n",
    "        self.train_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.train_prediction_dict[level] = np.zeros((train_prediction_shape[0],\n",
    "                                                          train_prediction_shape[1] * len(self.model_dict[level])))\n",
    "\n",
    "        for level in range(self.levels):\n",
    "\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "                validation_scores = []\n",
    "                foldnum = 1\n",
    "                for train_index, valid_index in kf.split(self.train_prediction_dict[0], self.y_enc):\n",
    "                    logger.info(\"Training Level %d Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if level != 0:\n",
    "                        l_training_data = temp_train[train_index]\n",
    "                        l_validation_data = temp_train[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "                    else:\n",
    "                        l0_training_data = temp_train[0][model_num]\n",
    "                        if type(l0_training_data) == list:\n",
    "                            l_training_data = [x[train_index] for x in l0_training_data]\n",
    "                            l_validation_data = [x[valid_index] for x in l0_training_data]\n",
    "                        else:\n",
    "                            l_training_data = l0_training_data[train_index]\n",
    "                            l_validation_data = l0_training_data[valid_index]\n",
    "                        model.fit(l_training_data, self.y_enc[train_index])\n",
    "\n",
    "                    logger.info(\"Predicting Level %d. Fold # %d. Model # %d\", level, foldnum, model_num)\n",
    "\n",
    "                    if self.task_type == 'classification':\n",
    "                        temp_train_predictions = model.predict_proba(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index,\n",
    "                        (model_num * self.num_classes):(model_num * self.num_classes) +\n",
    "                                                       self.num_classes] = temp_train_predictions\n",
    "\n",
    "                    else:\n",
    "                        temp_train_predictions = model.predict(l_validation_data)\n",
    "                        self.train_prediction_dict[level][valid_index, model_num] = temp_train_predictions\n",
    "                    validation_score = self.optimize(self.y_enc[valid_index], temp_train_predictions)\n",
    "                    validation_scores.append(validation_score)\n",
    "                    logger.info(\"Level %d. Fold # %d. Model # %d. Validation Score = %f\", level, foldnum, model_num,\n",
    "                                validation_score)\n",
    "                    foldnum += 1\n",
    "                avg_score = np.mean(validation_scores)\n",
    "                std_score = np.std(validation_scores)\n",
    "                logger.info(\"Level %d. Model # %d. Mean Score = %f. Std Dev = %f\", level, model_num,\n",
    "                            avg_score, std_score)\n",
    "\n",
    "            logger.info(\"Saving predictions for level # %d\", level)\n",
    "            train_predictions_df = pd.DataFrame(self.train_prediction_dict[level])\n",
    "            train_predictions_df.to_csv(os.path.join(self.save_path, \"train_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                        index=False, header=None)\n",
    "\n",
    "        return self.train_prediction_dict\n",
    "\n",
    "    def predict(self, test_data, lentest):\n",
    "        self.test_data = test_data\n",
    "        if self.task_type == 'classification':\n",
    "            test_prediction_shape = (lentest, self.num_classes)\n",
    "        else:\n",
    "            test_prediction_shape = (lentest, 1)\n",
    "\n",
    "        self.test_prediction_dict = {}\n",
    "        for level in range(self.levels):\n",
    "            self.test_prediction_dict[level] = np.zeros((test_prediction_shape[0],\n",
    "                                                         test_prediction_shape[1] * len(self.model_dict[level])))\n",
    "        self.test_data = test_data\n",
    "        for level in range(self.levels):\n",
    "            if level == 0:\n",
    "                temp_train = self.training_data\n",
    "                temp_test = self.test_data\n",
    "            else:\n",
    "                temp_train = self.train_prediction_dict[level - 1]\n",
    "                temp_test = self.test_prediction_dict[level - 1]\n",
    "\n",
    "            for model_num, model in enumerate(self.model_dict[level]):\n",
    "\n",
    "                logger.info(\"Training Fulldata Level %d. Model # %d\", level, model_num)\n",
    "                if level == 0:\n",
    "                    model.fit(temp_train[0][model_num], self.y_enc)\n",
    "                else:\n",
    "                    model.fit(temp_train, self.y_enc)\n",
    "\n",
    "                logger.info(\"Predicting Test Level %d. Model # %d\", level, model_num)\n",
    "\n",
    "                if self.task_type == 'classification':\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict_proba(temp_test)\n",
    "                    self.test_prediction_dict[level][:, (model_num * self.num_classes): (model_num * self.num_classes) +\n",
    "                                                                                        self.num_classes] = temp_test_predictions\n",
    "\n",
    "                else:\n",
    "                    if level == 0:\n",
    "                        temp_test_predictions = model.predict(temp_test[0][model_num])\n",
    "                    else:\n",
    "                        temp_test_predictions = model.predict(temp_test)\n",
    "                    self.test_prediction_dict[level][:, model_num] = temp_test_predictions\n",
    "\n",
    "            test_predictions_df = pd.DataFrame(self.test_prediction_dict[level])\n",
    "            test_predictions_df.to_csv(os.path.join(self.save_path, \"test_predictions_level_\" + str(level) + \".csv\"),\n",
    "                                       index=False, header=None)\n",
    "\n",
    "        return self.test_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:40:21] INFO Found 3 classes\n",
      "[12:40:21] INFO Training Level 0 Fold # 1. Model # 0\n",
      "[12:40:21] INFO Predicting Level 0. Fold # 1. Model # 0\n",
      "[12:40:21] INFO Level 0. Fold # 1. Model # 0. Validation Score = 0.582691\n",
      "[12:40:21] INFO Training Level 0 Fold # 2. Model # 0\n",
      "[12:40:22] INFO Predicting Level 0. Fold # 2. Model # 0\n",
      "[12:40:22] INFO Level 0. Fold # 2. Model # 0. Validation Score = 0.579270\n",
      "[12:40:22] INFO Training Level 0 Fold # 3. Model # 0\n",
      "[12:40:22] INFO Predicting Level 0. Fold # 3. Model # 0\n",
      "[12:40:22] INFO Level 0. Fold # 3. Model # 0. Validation Score = 0.580537\n",
      "[12:40:22] INFO Level 0. Model # 0. Mean Score = 0.580833. Std Dev = 0.001412\n",
      "[12:40:22] INFO Training Level 0 Fold # 1. Model # 1\n",
      "[12:40:30] INFO Predicting Level 0. Fold # 1. Model # 1\n",
      "[12:40:30] INFO Level 0. Fold # 1. Model # 1. Validation Score = 0.693722\n",
      "[12:40:30] INFO Training Level 0 Fold # 2. Model # 1\n",
      "[12:40:38] INFO Predicting Level 0. Fold # 2. Model # 1\n",
      "[12:40:38] INFO Level 0. Fold # 2. Model # 1. Validation Score = 0.688885\n",
      "[12:40:38] INFO Training Level 0 Fold # 3. Model # 1\n",
      "[12:40:46] INFO Predicting Level 0. Fold # 3. Model # 1\n",
      "[12:40:46] INFO Level 0. Fold # 3. Model # 1. Validation Score = 0.698811\n",
      "[12:40:46] INFO Level 0. Model # 1. Mean Score = 0.693806. Std Dev = 0.004053\n",
      "[12:40:46] INFO Training Level 0 Fold # 1. Model # 2\n",
      "[12:40:46] INFO Predicting Level 0. Fold # 1. Model # 2\n",
      "[12:40:46] INFO Level 0. Fold # 1. Model # 2. Validation Score = 0.640646\n",
      "[12:40:46] INFO Training Level 0 Fold # 2. Model # 2\n",
      "[12:40:46] INFO Predicting Level 0. Fold # 2. Model # 2\n",
      "[12:40:46] INFO Level 0. Fold # 2. Model # 2. Validation Score = 0.625461\n",
      "[12:40:46] INFO Training Level 0 Fold # 3. Model # 2\n",
      "[12:40:46] INFO Predicting Level 0. Fold # 3. Model # 2\n",
      "[12:40:46] INFO Level 0. Fold # 3. Model # 2. Validation Score = 0.644635\n",
      "[12:40:46] INFO Level 0. Model # 2. Mean Score = 0.636914. Std Dev = 0.008261\n",
      "[12:40:46] INFO Training Level 0 Fold # 1. Model # 3\n",
      "[12:40:47] INFO Predicting Level 0. Fold # 1. Model # 3\n",
      "[12:40:47] INFO Level 0. Fold # 1. Model # 3. Validation Score = 3.319563\n",
      "[12:40:47] INFO Training Level 0 Fold # 2. Model # 3\n",
      "[12:40:47] INFO Predicting Level 0. Fold # 2. Model # 3\n",
      "[12:40:47] INFO Level 0. Fold # 2. Model # 3. Validation Score = 3.327412\n",
      "[12:40:47] INFO Training Level 0 Fold # 3. Model # 3\n",
      "[12:40:47] INFO Predicting Level 0. Fold # 3. Model # 3\n",
      "[12:40:47] INFO Level 0. Fold # 3. Model # 3. Validation Score = 3.347928\n",
      "[12:40:47] INFO Level 0. Model # 3. Mean Score = 3.331634. Std Dev = 0.011958\n",
      "[12:40:47] INFO Saving predictions for level # 0\n",
      "[12:40:47] INFO Training Level 1 Fold # 1. Model # 0\n",
      "[12:40:48] INFO Predicting Level 1. Fold # 1. Model # 0\n",
      "[12:40:48] INFO Level 1. Fold # 1. Model # 0. Validation Score = 0.796838\n",
      "[12:40:48] INFO Training Level 1 Fold # 2. Model # 0\n",
      "[12:40:48] INFO Predicting Level 1. Fold # 2. Model # 0\n",
      "[12:40:48] INFO Level 1. Fold # 2. Model # 0. Validation Score = 0.765252\n",
      "[12:40:48] INFO Training Level 1 Fold # 3. Model # 0\n",
      "[12:40:49] INFO Predicting Level 1. Fold # 3. Model # 0\n",
      "[12:40:49] INFO Level 1. Fold # 3. Model # 0. Validation Score = 0.781462\n",
      "[12:40:49] INFO Level 1. Model # 0. Mean Score = 0.781184. Std Dev = 0.012897\n",
      "[12:40:49] INFO Saving predictions for level # 1\n",
      "[12:40:49] INFO Training Fulldata Level 0. Model # 0\n",
      "[12:40:50] INFO Predicting Test Level 0. Model # 0\n",
      "[12:40:50] INFO Training Fulldata Level 0. Model # 1\n",
      "[12:40:59] INFO Predicting Test Level 0. Model # 1\n",
      "[12:40:59] INFO Training Fulldata Level 0. Model # 2\n",
      "[12:40:59] INFO Predicting Test Level 0. Model # 2\n",
      "[12:40:59] INFO Training Fulldata Level 0. Model # 3\n",
      "[12:40:59] INFO Predicting Test Level 0. Model # 3\n",
      "[12:40:59] INFO Training Fulldata Level 1. Model # 0\n",
      "[12:41:00] INFO Predicting Test Level 1. Model # 0\n"
     ]
    }
   ],
   "source": [
    "# specify the data to be used for every level of ensembling:\n",
    "train_data_dict = {0: [xtrain_tfv, xtrain_ctv, xtrain_tfv, xtrain_ctv], 1: [xtrain_glove]}\n",
    "test_data_dict = {0: [xvalid_tfv, xvalid_ctv, xvalid_tfv, xvalid_ctv], 1: [xvalid_glove]}\n",
    "\n",
    "model_dict = {0: [LogisticRegression(), LogisticRegression(), MultinomialNB(alpha=0.1), MultinomialNB()],\n",
    "\n",
    "              1: [xgb.XGBClassifier(silent=True, n_estimators=120, max_depth=7)]}\n",
    "\n",
    "ens = Ensembler(model_dict=model_dict, num_folds=3, task_type='classification',\n",
    "                optimize=multiclass_logloss, lower_is_better=True, save_path='./')\n",
    "\n",
    "ens.fit(train_data_dict, ytrain, lentrain=xtrain_glove.shape[0])\n",
    "preds = ens.predict(test_data_dict, lentest=xvalid_glove.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[1.19115934e-01, 8.71690937e-01, 9.19312909e-03, ...,\n",
       "         9.87111768e-04, 9.99012888e-01, 3.70368977e-37],\n",
       "        [3.20562409e-01, 6.62145289e-01, 1.72923027e-02, ...,\n",
       "         2.41173872e-02, 9.75882613e-01, 2.93887953e-37],\n",
       "        [1.12004538e-01, 8.80483236e-01, 7.51222584e-03, ...,\n",
       "         6.38505690e-20, 1.00000000e+00, 7.11279159e-77],\n",
       "        ...,\n",
       "        [1.29229780e-01, 8.58090698e-01, 1.26795216e-02, ...,\n",
       "         1.62375245e-06, 9.99998376e-01, 1.91422431e-40],\n",
       "        [4.42480122e-01, 5.36613025e-01, 2.09068523e-02, ...,\n",
       "         9.99817547e-01, 1.82452803e-04, 4.07985734e-27],\n",
       "        [1.88004296e-01, 8.03313417e-01, 8.68228698e-03, ...,\n",
       "         1.75907028e-12, 1.00000000e+00, 1.55564351e-71]]),\n",
       " 1: array([[7.88316038e-03, 9.92106080e-01, 1.07203859e-05],\n",
       "        [1.96564108e-01, 8.02066684e-01, 1.36921543e-03],\n",
       "        [1.40753854e-02, 9.85908449e-01, 1.61019580e-05],\n",
       "        ...,\n",
       "        [5.81979239e-03, 9.94171321e-01, 8.87629358e-06],\n",
       "        [2.02699900e-01, 7.97143936e-01, 1.56170267e-04],\n",
       "        [1.48066469e-02, 9.85181868e-01, 1.14980830e-05]])}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Prediction Sequence 1/4\n",
    "# test_predictions = model.predict_proba(xtest_pad)\n",
    "labels = np.argmax(preds, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011\n"
     ]
    }
   ],
   "source": [
    "# Test Prediction Sequence 2/4\n",
    "subNumber += 1\n",
    "submission = pd.DataFrame({'id': sample['id'], 'ratingCategory':labels})\n",
    "# submission['ratingCategory'] = submission['ratingCategory'].astype('int64')\n",
    "submission.to_csv(f'../data/deepsub{subNumber}.csv', index=False)\n",
    "print(subNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1022\n",
       "Name: ratingCategory, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Prediction Sequence 3/4\n",
    "submission['ratingCategory'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARDElEQVR4nO3de9BdVX3G8e8jARFULuYdqgltGGXoUGtFI2Lt2I54A6uhVlGmlmiZSWdKvVTbGtvO0GovWrVUpWUaBQwOWrmoYMdqKaJOraCJIAbQmkGRRC6viog6aKO//nFWygET1gnknPO+Od/PzJl37bXW3ucXEvJkr73PPqkqJEm6Lw+adgGSpIXPsJAkdRkWkqQuw0KS1GVYSJK6lky7gHFYunRprVixYtplSNKisnHjxm9V1dyOxvbIsFixYgUbNmyYdhmStKgkuXFnYy5DSZK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuvbIT3A/UE/8k3OnXYIk3S8b33LyWI47tjOLJGcnuS3JpqG+g5NcmuSr7edBrT9J3pFkc5JrkjxhaJ/Vbf5Xk6weV72SpJ0b5zLUe4Dn3KtvLXBZVR0OXNa2AY4DDm+vNcCZMAgX4DTgycDRwGnbA0aSNDljC4uq+jTwnXt1rwLWt/Z64ISh/nNr4ArgwCSPBJ4NXFpV36mq24FL+dkAkiSN2aQvcB9SVTe39i3AIa29DLhpaN6W1rez/p+RZE2SDUk2zM/P796qJWnGTe1uqKoqoHbj8dZV1cqqWjk3t8PHsUuS7qdJh8WtbXmJ9vO21r8VOHRo3vLWt7N+SdIETTosLgG239G0Grh4qP/kdlfUMcAdbbnq48CzkhzULmw/q/VJkiZobJ+zSPJ+4DeApUm2MLir6U3A+UlOAW4ETmzTPwocD2wGfgi8HKCqvpPkjcDn27w3VNW9L5pLksZsbGFRVSftZOjYHcwt4NSdHOds4OzdWJokaRf5uA9JUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuqYSFkn+KMm1STYleX+SfZMcluTKJJuTfCDJPm3ug9v25ja+Yho1S9Ism3hYJFkGvBJYWVWPBfYCXgK8GTi9qh4D3A6c0nY5Bbi99Z/e5kmSJmhay1BLgIckWQLsB9wMPB24sI2vB05o7VVtmzZ+bJJMsFZJmnkTD4uq2gq8FfgGg5C4A9gIfLeqtrVpW4Blrb0MuKntu63Nf8S9j5tkTZINSTbMz8+P9xchSTNmGstQBzE4WzgMeBSwP/CcB3rcqlpXVSurauXc3NwDPZwkacg0lqGeAXytquar6n+BDwJPBQ5sy1IAy4Gtrb0VOBSgjR8AfHuyJUvSbJtGWHwDOCbJfu3aw7HAdcDlwAvbnNXAxa19SdumjX+iqmqC9UrSzJvGNYsrGVyo/gLwpVbDOuB1wGuSbGZwTeKststZwCNa/2uAtZOuWZJm3ZL+lN2vqk4DTrtX9w3A0TuYexfwoknUJUnaMT/BLUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuqYSFkkOTHJhki8nuT7JU5IcnOTSJF9tPw9qc5PkHUk2J7kmyROmUbMkzbJpnVm8HfhYVf0i8CvA9cBa4LKqOhy4rG0DHAcc3l5rgDMnX64kzbaJh0WSA4CnAWcBVNWPq+q7wCpgfZu2HjihtVcB59bAFcCBSR454bIlaaZN48ziMGAeOCfJVUnenWR/4JCqurnNuQU4pLWXATcN7b+l9d1DkjVJNiTZMD8/P8byJWn2TCMslgBPAM6sqqOAH3D3khMAVVVA7cpBq2pdVa2sqpVzc3O7rVhJ0ohhkeSyUfpGtAXYUlVXtu0LGYTHrduXl9rP29r4VuDQof2Xtz5J0oTcZ1gk2TfJwcDSJAe1O5YOTrKCHSwFjaKqbgFuSnJE6zoWuA64BFjd+lYDF7f2JcDJ7a6oY4A7hparJEkTsKQz/vvAq4FHARuBtP7vAWc8gPd9BXBekn2AG4CXMwiu85OcAtwInNjmfhQ4HtgM/LDNlSRN0H2GRVW9HXh7kldU1Tt315tW1dXAyh0MHbuDuQWcurveW5K063pnFgBU1TuT/CqwYnifqjp3THVJkhaQkcIiyXuBRwNXAz9p3QUYFpI0A0YKCwZLRke2JSFJ0owZ9XMWm4CfG2chkqSFa9Qzi6XAdUk+B/xoe2dVPX8sVUmSFpRRw+Ivx1mEJGlhG/VuqE+NuxBJ0sI16t1Qd3L3s5r2AfYGflBVDx9XYZKkhWPUM4uHbW8nCYPHhh8zrqIkSQvLLj91tn2vxIeBZ4+hHknSAjTqMtQLhjYfxOBzF3eNpSJJ0oIz6t1QzxtqbwO+zmApSpI0A0a9ZuGTXiVpho365UfLk3woyW3tdVGS5eMuTpK0MIx6gfscBl9C9Kj2+kjrkyTNgFHDYq6qzqmqbe31HsAvupakGTFqWHw7yUuT7NVeLwW+Pc7CJEkLx6hh8XsMvub0FuBm4IXAy8ZUkyRpgRn11tk3AKur6naAJAcDb2UQIpKkPdyoZxaP2x4UAFX1HeCo8ZQkSVpoRg2LByU5aPtGO7MY9axEkrTIjfoX/tuAzya5oG2/CPib8ZQkSVpoRv0E97lJNgBPb10vqKrrxleWJGkhGXkpqYWDASFJM2iXH1EuSZo9hoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeqaWli078W4Ksm/te3DklyZZHOSDyTZp/U/uG1vbuMrplWzJM2qaZ5ZvAq4fmj7zcDpVfUY4HbglNZ/CnB76z+9zZMkTdBUwiLJcuC5wLvbdhg8d+rCNmU9cEJrr2rbtPFj23xJ0oRM68ziH4E/BX7ath8BfLeqtrXtLcCy1l4G3ATQxu9o8+8hyZokG5JsmJ+fH2ftkjRzJh4WSX4TuK2qNu7O41bVuqpaWVUr5+bmduehJWnmTeMLjJ4KPD/J8cC+wMOBtwMHJlnSzh6WA1vb/K3AocCWJEuAA4BvT75sSZpdEz+zqKrXV9XyqloBvAT4RFX9DnA58MI2bTVwcWtf0rZp45+oqppgyZI08xbS5yxeB7wmyWYG1yTOav1nAY9o/a8B1k6pPkmaWVP9Hu2q+iTwyda+ATh6B3PuYvA1rpKkKVlIZxaSpAXKsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqmnhYJDk0yeVJrktybZJXtf6Dk1ya5Kvt50GtP0nekWRzkmuSPGHSNUvSrJvGmcU24LVVdSRwDHBqkiOBtcBlVXU4cFnbBjgOOLy91gBnTr5kSZptEw+Lqrq5qr7Q2ncC1wPLgFXA+jZtPXBCa68Czq2BK4ADkzxywmVL0kyb6jWLJCuAo4ArgUOq6uY2dAtwSGsvA24a2m1L67v3sdYk2ZBkw/z8/NhqlqRZNLWwSPJQ4CLg1VX1veGxqiqgduV4VbWuqlZW1cq5ubndWKkkaSphkWRvBkFxXlV9sHXfun15qf28rfVvBQ4d2n1565MkTcg07oYKcBZwfVX9w9DQJcDq1l4NXDzUf3K7K+oY4I6h5SpJ0gQsmcJ7PhX4XeBLSa5ufX8GvAk4P8kpwI3AiW3so8DxwGbgh8DLJ1uuJGniYVFV/wVkJ8PH7mB+AaeOtShJ0n3yE9ySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdS2asEjynCRfSbI5ydpp1yNJs2RRhEWSvYB/Ao4DjgROSnLkdKuSpNmxKMICOBrYXFU3VNWPgX8FVk25JkmaGUumXcCIlgE3DW1vAZ48PCHJGmBN2/x+kq9MqDZpVy0FvjXtIrRnyltXP5Ddf2FnA4slLLqqah2wbtp1SD1JNlTVymnXIe2KxbIMtRU4dGh7eeuTJE3AYgmLzwOHJzksyT7AS4BLplyTJM2MRbEMVVXbkvwh8HFgL+Dsqrp2ymVJ95fLpVp0UlXTrkGStMAtlmUoSdIUGRaSpC7DQpoQH1mjxcxrFtIEtEfW/A/wTAYfKv08cFJVXTfVwqQReWYhTYaPrNGiZlhIk7GjR9Ysm1It0i4zLCRJXYaFNBk+skaLmmEhTYaPrNGitige9yEtdj6yRoudt85KkrpchpIkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIQFJXp1kv6HtjyY58AEc7+gkn25Pmb0qybuHj7+D+Y9Pcvz9fT9p3AwLzYwM7OzP/KuB///LvKqOr6rv3s/3OQS4AHhdVR1RVUcBHwMedh+7PR4Ye1i0p99Ku8yw0B4tyYr2r/tzgU3AWUk2JLk2yV+1Oa8EHgVcnuTy1vf1JEvb/tcneVfb5z+SPKTNeVKSa5JcneQtSTa1tz0VWF9Vn91eR1VdWFW3tjOOz7azjf9OckT7RPcbgBe3Y704yf5Jzk7yuTZ3VXvP/ZKcn+S6JB9KcmWSlW3spCRfSrIpyZuH/ht8P8nbknwR+PMkHx4ae2aSD43tN0B7jqry5WuPfQErgJ8Cx7Ttg9vPvYBPAo9r218Hlg7t93Vgadt/G/D41n8+8NLW3gQ8pbXfBGxq7Q8Cq3ZSz8OBJa39DOCi1n4ZcMbQvL8dep8DGXwXxv7AHwP/0vof22pbySDsvgHMMXgywyeAE9q8Ak5s7QBfBuba9vuA503798nXwn95ZqFZcGNVXdHaJyb5AnAV8EvAkSPs/7Wqurq1NwIr2vWMh9XdZw/vG7GWA4AL2lnI6a2GHXkWsDbJ1QxCbV/g54FfY/BdGFTVJuCaNv9JwCerar6qtgHnAU9rYz8BLmr7FPBe4KXt1/AU4N9HrF0zzGdDaRb8ACDJYQz+Zf6kqro9yXsY/CXc86Oh9k+Ah3TmXws8Ebh4B2NvBC6vqt9KsoJBEOxIgN+uqq/cozMZodyfcVdV/WRo+xzgI8BdwAUtXKT75JmFZsnDGQTHHe0i9HFDY3dy3xeg76EGF7/vTPLk1vWSoeEzgNVDYyR5QXvPA7j70eQvu4/3/zjwirR0SHJU6/8McGLrOxL45db/OeDX23WWvYCTgE/tpPZvAt8E/oJBcEhdhoVmRlV9kcHy05cZLBt9Zmh4HfCx7Re4R3QK8K62VLQ/cEd7n1sZhMdb28X164FnMwiEvwf+LslV3PPM/nLgyO0XuBmcgewNXJPk2rYN8M/AXJLrgL9mcBZzR1XdDKxtx/kisLGqdnRms915wE1Vdf0u/Ho1w3zqrHQ/JXloVX2/tdcCj6yqV435PfcC9q6qu5I8GvhP4IgafK/3rhznDOCqqjprHHVqz+M1C+n+e26S1zP4/+hG7rmsNC77MbjFd28G1zX+4H4ExUYGy3GvHUN92kN5ZiFJ6vKahSSpy7CQJHUZFpKkLsNCktRlWEiSuv4PRMw0KYPDJDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prediction Sequence 4/4\n",
    "sns.countplot(x='ratingCategory', data=submission);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "any-nlp",
   "language": "python",
   "name": "any-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
